{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "#import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_dir='E:/深度学习/2\\inception-2015-12-05/model'\n",
    "image = 'E:/深度学习/2/inception-2015-12-05/images/cat.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NodeLookup(object):\n",
    "    def __init__(self, label_lookup_path=None, uid_lookup_path=None):\n",
    "        if not label_lookup_path:\n",
    "            # 加载“label_lookup_path”文件\n",
    "            label_lookup_path = os.path.join(\n",
    "                    model_dir, 'imagenet_2012_challenge_label_map_proto.pbtxt')\n",
    "        if not uid_lookup_path:\n",
    "            # 加载“uid_lookup_path”文件\n",
    "            uid_lookup_path = os.path.join(\n",
    "                    model_dir, 'imagenet_synset_to_human_label_map.txt')\n",
    "        self.node_lookup = self.load(label_lookup_path, uid_lookup_path)\n",
    "\n",
    "    def load(self, label_lookup_path, uid_lookup_path):\n",
    "        if not tf.gfile.Exists(uid_lookup_path):\n",
    "            # 预先检测地址是否存在\n",
    "            tf.logging.fatal('File does not exist %s', uid_lookup_path)\n",
    "        if not tf.gfile.Exists(label_lookup_path):\n",
    "            tf.logging.fatal('File does not exist %s', label_lookup_path)\n",
    "        proto_as_ascii_lines = tf.gfile.GFile(uid_lookup_path).readlines()\n",
    "        uid_to_human = {}\n",
    "        # 一行行读取数据\n",
    "        for line in proto_as_ascii_lines:\n",
    "            line = line.strip('\\n')\n",
    "            parse_items = line.split('\\t')\n",
    "            uid = parse_items[0]\n",
    "            human_string = parse_items[1]\n",
    "            uid_to_human[uid] = human_string\n",
    "        # 加载分类字符串\n",
    "        proto_as_ascii = tf.gfile.GFile(label_lookup_path).readlines()\n",
    "        # 创建空字典node_id_to_uid用以存储分类代码node ID与UID之间的关系\n",
    "        node_id_to_uid = {}\n",
    "        for line in proto_as_ascii:\n",
    "            if line.startswith('  target_class:'):\n",
    "                target_class = int(line.split(': ')[1])\n",
    "            if line.startswith('  target_class_string:'):\n",
    "                target_class_string = line.split(': ')[1]\n",
    "                node_id_to_uid[target_class] = target_class_string[1:-2]\n",
    "        # 加载node ID与分类名称之间的映射关系\n",
    "        node_id_to_name = {}\n",
    "        for key, val in node_id_to_uid.items():\n",
    "            if val not in uid_to_human:\n",
    "                tf.logging.fatal('Failed to locate: %s', val)\n",
    "            name = uid_to_human[val]\n",
    "            node_id_to_name[key] = name\n",
    "        return node_id_to_name\n",
    "    # 传入分类编号1-1000，返回分类具体名称\n",
    "    def id_to_string(self, node_id):\n",
    "        if node_id not in self.node_lookup:\n",
    "            return ''\n",
    "        return self.node_lookup[node_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 读取并创建一个图graph来存放Google训练好的Inception_v3模型（函数）\n",
    "def create_graph():\n",
    "    with tf.gfile.FastGFile(os.path.join(\n",
    "            model_dir, 'classify_image_graph_def.pb'), 'rb') as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "        tf.import_graph_def(graph_def, name='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#读取图片\n",
    "image_data = tf.gfile.FastGFile(image, 'rb').read()\n",
    "#创建graph\n",
    "create_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tabby, tabby cat (score = 0.52552)\n",
      "Egyptian cat (score = 0.21148)\n",
      "tiger cat (score = 0.16916)\n",
      "lynx, catamount (score = 0.01870)\n",
      "Persian cat (score = 0.00621)\n"
     ]
    }
   ],
   "source": [
    "# 创建会话，从已有的Inception_v3模型中恢复\n",
    "with tf.Session() as sess:\n",
    "    softmax_tensor = sess.graph.get_tensor_by_name('softmax:0')\n",
    "    predictions = sess.run(softmax_tensor,{'DecodeJpeg/contents:0': image_data})\n",
    "    predictions = np.squeeze(predictions)\n",
    "    node_lookup = NodeLookup()\n",
    "    top_5 = predictions.argsort()[-5:][::-1]\n",
    "    for node_id in top_5:\n",
    "        human_string = node_lookup.id_to_string(node_id)\n",
    "        score = predictions[node_id]\n",
    "        print('%s (score = %.5f)' % (human_string, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
